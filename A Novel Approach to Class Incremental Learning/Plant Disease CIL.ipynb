{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3d741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf    #with gpu version\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import splitfolders\n",
    "\n",
    "from tensorflow import keras    #with gpu version\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Rescaling\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2  \n",
    "from keras.applications.vgg19 import VGG19, preprocess_input \n",
    "from keras.callbacks import BackupAndRestore, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight \n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from numba import cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a81186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3100581976782060165\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3665166336\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7255887679826321343\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n",
      "Default GPU Device: /device:GPU:0\n",
      "If this outputs the matrix, then the GPU is working\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "#Check if gpu is involved\n",
    "\n",
    "#https://www.tensorflow.org/guide/gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "print(\"If this outputs the matrix, then the GPU is working\")\n",
    "#https://stackoverflow.com/questions/58289983/low-nvidia-gpu-usage-with-keras-and-tensorflow?rq=1\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "        print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea78048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "#for testing purposes\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222)\n",
    "\n",
    "example_flow = datagen.flow_from_directory(\n",
    "    directory = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Data\\Plant Village\\All\\test\",\n",
    "    batch_size = 1)\n",
    "\n",
    "#https://stackoverflow.com/questions/63355107/keras-imagedatagenerator-result-display-flow\n",
    "for _ in range(10):\n",
    "    img, label = example_flow.next()\n",
    "    print(img.shape)   #  (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6fe62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stick EDA here\n",
    "\n",
    "#Class counts\n",
    "#https://stackoverflow.com/questions/65632501/keras-flow-from-directory-how-to-get-number-of-samples-in-each-category\n",
    "\n",
    "imflow = ImageDataGenerator(rescale = 1./255).flow_from_directory(r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Data\\Plant Village\\Apples\\train\")\n",
    "counter = Counter(imflow.classes)  \n",
    "\n",
    "print(counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9342de",
   "metadata": {},
   "source": [
    "## Sub-Network Creation\n",
    "\n",
    "Here, the sub-networks, used later to comprise the full models, are created.  Each final model will have three plant specific sub-networks (apple, peach, and cherry leaf).  There will be four final models, Type-1 and Type-2, 'other'-inclusive and 'other'-exclusive.  \n",
    "\n",
    "Type-1 models will have only one layer of sub-networks wherein task identification and disease classification are performed by the same sub-networks.\n",
    "\n",
    "Type-2 models will have two layers of sub-networks.  The first layer will perform task-identification, the second disease classification.\n",
    "\n",
    "'Other' inclusive or exclusive pertains to how the task identifiying class is trained (included in each Type-1 sub-network, and each first layer type-2 sub-network).  Inclusive indicates that plant types represented as the target of a sub-network may be used to train the 'other' class (off-target) in other sub-networks within the model.  Exclusive indicates that examples of plant types which are the target of any sub-network in the model are not used for off-target identification in any of the sub-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1121f",
   "metadata": {},
   "source": [
    "### Type 1, Other Inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995681a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppleDiseaseOther_create():\n",
    "    #Apple Disease Other model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('AppleDiseaseOther_1_Weights.h5')  \n",
    "    model.save('AppleDiseaseOther_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "AppleDiseaseOtherMod1 = AppleDiseaseOther_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOther1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a092b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PeachDiseaseOther_create():\n",
    "    #Peach Disease Other model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('PeachDiseaseOther_1_Weights.h5')  \n",
    "    model.save('PeachDiseaseOther_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "PeachDiseaseOtherMod = PeachDiseaseOther_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOther1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CherryDiseaseOther_create():\n",
    "    #Cherry Disease Other model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('CherryDiseaseOther_1_Weights.h5')  \n",
    "    model.save('CherryDiseaseOther_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "CherryDiseaseOtherMod = CherryDiseaseOther_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d625f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOther')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen,\n",
    "                          workers = 32,\n",
    "                          max_queue_size = 64)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f83b49",
   "metadata": {},
   "source": [
    "### Type 1, Other-Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppleDiseaseOtherNoex_create():\n",
    "    #Apple Disease Other Noex model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('AppleDiseaseOtherNoex_1_Weights.h5')  \n",
    "    model.save('AppleDiseaseOtherNoex_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "AppleDiseaseOtherNoexMod1 = AppleDiseaseOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOtherNoex1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\AppleDiseaseOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen,\n",
    "                          workers = 32,\n",
    "                          max_queue_size = 64)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PeachDiseaseOtherNoex_create():\n",
    "    #Peach Disease Other Noex model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('PeachDiseaseOtherNoex_1_Weights.h5')  \n",
    "    model.save('PeachDiseaseOtherNoex_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "PeachDiseaseOtherNoexMod1 = PeachDiseaseOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOtherNoex')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\PeachDiseaseOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen,\n",
    "                          workers = 32,\n",
    "                          max_queue_size = 64)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98fe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CherryDiseaseOtherNoex_create():\n",
    "    #Peach Disease Other Noex model 1\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('CherryDiseaseOtherNoex_1_Weights.h5')  \n",
    "    model.save('CherryDiseaseOtherNoex_1_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "CherryDiseaseOtherNoexMod1 = CherryDiseaseOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOtherNoex')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\CherryDiseaseOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen,\n",
    "                          workers = 32,\n",
    "                          max_queue_size = 64)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f759084",
   "metadata": {},
   "source": [
    "### Type-2, Other Inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppleOther_create():\n",
    "    #Apple Other model 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=35,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('AppleOther_Weights.h5')  \n",
    "    model.save('AppleOther_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "AppleOtherMod = AppleOther_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a472cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOther2')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\AppleOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee208ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PeachesOther_create():\n",
    "    #PeachesOther model 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachesOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachesOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachesOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0005, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('PeachesOther_Weights.h5')  \n",
    "    model.save('PeachesOther_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "PeachesOtherMod = PeachesOther_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachesOther')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\PeachesOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09693f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CherryOther_create():\n",
    "    #Cherry Other model 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryOther\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryOther\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('CherryOther_Weights.h5')  \n",
    "    model.save('CherryOther_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "CherryOtherMod1 = CherryOther_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\CherryOther_Model.h5')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\CherryOther\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen,\n",
    "                          max_queue_size = 64,\n",
    "                          workers = 32)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba5344",
   "metadata": {},
   "source": [
    "### Type-2, Other Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8602855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppleOtherNoex_create():\n",
    "    #Apple Other Noex 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\AppleOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('AppleOtherNoex_Weights.h5')  \n",
    "    model.save('AppleOthreNoex_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "AppleOtherNoex1 = AppleOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0453f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOtherNoex1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\AppleOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37673e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PeachOtherNoex_create():\n",
    "    #Peach Other Noex 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\PeachOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('PeachOtherNoex_Weights.h5')  \n",
    "    model.save('PeachOtherNoex_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "PeachOtherNoex1 = PeachOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e49d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachOtherNoex1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\PeachOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712daac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CherryOtherNoex_create():\n",
    "    #Cherry Other Noex 1\n",
    "    #Would filter images before a disease classifier\n",
    "    #\n",
    "    \n",
    "    ########################################################################################\n",
    "    #First, define the model structure\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(include_top = False, input_shape = (224,224,3)))  #Loads Mobilenet Layers, without the top layer\n",
    "\n",
    "    model.get_layer(\"mobilenetv2_1.00_224\").trainable = False  #We'll keep the weights from mobilenetV2\n",
    "    model.add(Flatten())   #These next bits flatten the output from the mobilenet (without the top layer), and add add a couple dense layers which we train on the apple data\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))  #Softmax for multiclass classification\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',   # I hear this one works well\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #######################################################################################\n",
    "    #Took some code from link below\n",
    "    #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "    \n",
    "    #batches of 32 images @ 256^2 pixels seems to work well with my gpu. About twice as fast as running on cpu\n",
    "    batchsize = 32\n",
    "\n",
    "    #Specifies the range of augmentation for all images (preprocessing)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = (0.6,1.3),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.22222) #this ends up being about 20% of the entire dataset (we seperate testing prior to anything)\n",
    "\n",
    "    #Sets the training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"training\")\n",
    "\n",
    "\n",
    "    #Sets the validation data generator\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        directory = r\"C:\\Datasets\\Plant Village\\CherryOtherNoex\\train\",\n",
    "        target_size = (224,224),\n",
    "        batch_size = batchsize,\n",
    "        class_mode = \"categorical\",\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    \n",
    "    #Get's class weights\n",
    "    #https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "\n",
    "    train_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "\n",
    "    \n",
    "    ################################################################33\n",
    "    #This fits the model \n",
    "    checkpoint_path = r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryOtherNoex\" #path for checkpoints\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0, min_delta = 0.0002, verbose = 1), #Reduces the learning rate if no improvements are made.  Hopefully make for a more accurate model\n",
    "                 ModelCheckpoint(filepath = checkpoint_path, monitor = \"val_accuracy\", verbose = 1, save_best_only = True, mode = \"auto\", save_freq = \"epoch\") #Saves the model when it performes best\n",
    "                ] \n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(train_generator.samples / batchsize),\n",
    "        epochs=25,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=np.ceil(val_generator.samples / batchsize),\n",
    "        class_weight=train_class_weights,\n",
    "        workers = 32,\n",
    "        #use_multiprocessing = True,\n",
    "        max_queue_size = 64,\n",
    "        callbacks = callbacks\n",
    "        \n",
    "        )\n",
    "\n",
    "    #Saves it\n",
    "    model.save_weights('CherryOtherNoex_Weights.h5')  \n",
    "    model.save('CherryOtherNoex_Model.h5')  \n",
    "    \n",
    "    return model\n",
    "\n",
    "CherryOtherNoex1 = CherryOtherNoex_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the test set\n",
    "testmodel = keras.models.load_model(r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryOtherNoex1')\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = r\"C:\\Datasets\\Plant Village\\PeachOtherNoex\\test\",\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\",\n",
    "\n",
    "metrics = tf.keras.models.Model.evaluate(testmodel,\n",
    "                  testgen)\n",
    "\n",
    "print(\"Loss: \" + str(round(metrics[0],4)), \"Accuracy: \" + str(round(metrics[1],4)))\n",
    "\n",
    "#https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = testmodel.predict(testgen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45763d7",
   "metadata": {},
   "source": [
    "## Sub-Network Consolidation Functions\n",
    "\n",
    "Below are the functions that take the sub-networks generated previusly, and combine them into full models that can handle multiple types of plants.  There are two functions, one for both Type-1 and Type-2 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa092bb1",
   "metadata": {},
   "source": [
    "### Model Type-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_type_1(mod_paths, test_path, plants, class_nums, batch_size = 8, eval_mode = False):\n",
    "    \n",
    "    \n",
    "    #######################\n",
    "    #Load in the data and process it\n",
    "    \n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(test_path,\n",
    "                                                                 image_size = (224, 224),\n",
    "                                                                 shuffle = False,\n",
    "                                                                 label_mode = \"categorical\",\n",
    "                                                                 batch_size = batch_size)\n",
    "    #Rescaling (because we didn't build it into the models)\n",
    "    #https://github.com/tensorflow/tensorflow/issues/39595\n",
    "    rescale = Rescaling(scale=1.0/255)\n",
    "    dataset = dataset.map(lambda image,label:(rescale(image),label))\n",
    "    \n",
    "    \n",
    "    ##################################################################################\n",
    "    #Load the models, make predictions, save them together \n",
    "    \n",
    "    compiled_preds = pd.DataFrame()\n",
    "    for mod_path, predifex, classes in zip(mod_paths, plants, class_nums):\n",
    "\n",
    "        \n",
    "        testmodel = keras.models.load_model(mod_path)\n",
    "\n",
    "        preds = testmodel.predict(dataset,\n",
    "                         workers = 32,\n",
    "                         max_queue_size = 32,\n",
    "                         verbose = 1)\n",
    "\n",
    "\n",
    "        #Yeah.  You'd think there would be a simpler way to do this.  Probably is.\n",
    "        cols = list(chain(*[[predifex + str(x) for x in range(classes)], [\"not\" + predifex]]))\n",
    "        compiled_preds = pd.DataFrame(preds, columns = cols).join(compiled_preds)\n",
    "        \n",
    "    \n",
    "    ###########################################################################\n",
    "    #seperates out the best predictions for the most likely plant\n",
    "    \n",
    "    #Finds least likely 'other' among all predictions.  Removes 'not', yielding a list of most likely plant\n",
    "    plant_labels = compiled_preds.filter(regex=\"not\").idxmin(axis = 1).str.replace(\"not\",\"\") \n",
    "\n",
    "\n",
    "    selected_preds = pd.DataFrame(plant_labels, columns = [\"plant\"]) #dataframe with plant labels\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(plant_labels):\n",
    "\n",
    "        #Below will append the disease label (0,1,2, etc) for the appropriate plant to a dataframe containing the plant\n",
    "        #regex expression from: https://stackoverflow.com/questions/406230/regular-expression-to-match-a-line-that-doesnt-contain-a-word\n",
    "        selected_preds.loc[i,\"disease\"] = compiled_preds.loc[i,:].filter(regex=plant_labels[i]).filter(regex = \"^((?!not).)*$\").idxmax(axis = 1).replace(plant_labels[i],\"\")\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    ####################################################\n",
    "    #Adds an absolute label to help make confusion matrices\n",
    "    #Will go in order specified by order of paths/plant names.  make sure they lign up with the test-data directory\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(plants):\n",
    "\n",
    "        plant = plants[i]\n",
    "        add = sum(class_nums[0:i])\n",
    "\n",
    "        selected_preds.loc[selected_preds[\"plant\"] == plant,\"absolute_label\"] = pd.to_numeric(selected_preds[\"disease\"]) + add\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "    #Return\n",
    "    if eval_mode == False: #Standard classified results, with both absolute labels and classes per plant\n",
    "    \n",
    "        return selected_preds\n",
    "    \n",
    "    elif eval_mode == True:\n",
    "        \n",
    "        return compiled_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the variables here ordered in accordance to the way data dirctories are arranged\n",
    "\n",
    "#Paths can either be .h5 or pb\n",
    "mod_paths = [r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOtherNoex1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOtherNoex1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOtherNoex1\"]\n",
    "\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "plants = [\"Apple\", \"Cherry\", \"Peach\"]\n",
    "\n",
    "class_nums = [4,2,2]\n",
    "\n",
    "predictions = model_type_1(mod_paths, test_path, plants, class_nums, eval_mode = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b82eb",
   "metadata": {},
   "source": [
    "### Model Type-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c55aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_type_2(layer1List, layer2List, testpath, plants, eval_mode = False, eval_class_nums = [], batch_size = 8):\n",
    "    \n",
    "    #Notes:\n",
    "    #OOM errors with batch sizes of 32+\n",
    "    \n",
    "    #One big inneficiency with this is that it runs all data through all 2nd layer models\n",
    "    #It's very difficult to filter the dataset so only appropriate data gets passed to respective 2nd layer models\n",
    "    #Should probably try improving it again (good luck)\n",
    "\n",
    "    #######################\n",
    "    #Load in the data and process it\n",
    "                                                                              ###############################################################################\n",
    "    img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)#Why is this in here?  Remove and see if it breaks things next time \n",
    "\n",
    "\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(testpath,\n",
    "                                                                 image_size = (224, 224),\n",
    "                                                                 shuffle = False,\n",
    "                                                                 label_mode = \"categorical\",\n",
    "                                                                 batch_size = batch_size)\n",
    "    #Rescaling (because we didn't build it into the models)\n",
    "    #https://github.com/tensorflow/tensorflow/issues/39595\n",
    "    rescale = Rescaling(scale=1.0/255)\n",
    "    dataset = dataset.map(lambda image,label:(rescale(image),label))\n",
    "\n",
    "    ##########################\n",
    "    #Load the layer 1 models, make predictions, save them \n",
    "    \n",
    "    compiled_preds_layer1 = pd.DataFrame()\n",
    "    for mod_path, predifex in zip(layer1List, plants):\n",
    "\n",
    "        \n",
    "        testmodel = keras.models.load_model(mod_path)\n",
    "\n",
    "        preds = testmodel.predict(dataset,\n",
    "                         workers = 32,\n",
    "                         max_queue_size = 32,\n",
    "                         verbose = 1)\n",
    "\n",
    "\n",
    "        #We're going to take the highest certaintty from all models.   basically argmax on a compiled preiction set \n",
    "       \n",
    "        compiled_preds_layer1 = pd.DataFrame(preds, columns = [predifex, \"not\" + predifex]).join(compiled_preds_layer1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    #Load the layer 2 models, make predictions all data for each (inefficient)\n",
    "    \n",
    "    preds_layer2 = pd.DataFrame()\n",
    "    for mod_path, predifex in zip(layer2List, plants):\n",
    "\n",
    "        \n",
    "        testmodel = keras.models.load_model(mod_path)\n",
    "        \n",
    "        preds = testmodel.predict(dataset,\n",
    "                         workers = 32,\n",
    "                         max_queue_size = 32,\n",
    "                         verbose = 1)\n",
    "        \n",
    "        best_preds = np.argmax(preds, axis = 1)\n",
    "        \n",
    "        preds_layer2[predifex] = best_preds\n",
    "        \n",
    "        \n",
    "    ###############################################\n",
    "    #The first output will return all the results with a plant's diseases in one column for each possible plant, and a key for distinguishing between the type of plant\n",
    "    \n",
    "    plant_key = compiled_preds_layer1[compiled_preds_layer1.columns.drop(list(compiled_preds_layer1.filter(regex='not')))].idxmax(axis=\"columns\")\n",
    "    preds_layer2[\"plant_key\"] = plant_key\n",
    "    total_results_with_key = preds_layer2\n",
    "    \n",
    "    #Returns predicted classes across all plants with diseases ordered in absolute fasion (depending on what models ran first)\n",
    "    if eval_mode == False:\n",
    "    \n",
    "        predictions_absolute_labels = preds_layer2\n",
    "        i = 1\n",
    "        \n",
    "        while i < len(eval_class_nums):\n",
    "\n",
    "            predictions_absolute_labels.iloc[:,i] += sum(eval_class_nums[:i])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        \n",
    "        #When in doubt, loop\n",
    "        #There's probably somthing out there that does this more cleanly\n",
    "        row = 0\n",
    "        while row < len(predictions_absolute_labels):\n",
    "\n",
    "            col = 0\n",
    "            while col < len(plants):\n",
    "\n",
    "                if predictions_absolute_labels.columns[col] == predictions_absolute_labels.loc[row,\"plant_key\"]:\n",
    "                    predictions_absolute_labels.loc[row,\"absolute\"] = int(predictions_absolute_labels.iloc[row,col])\n",
    "\n",
    "                col += 1\n",
    "\n",
    "            row += 1\n",
    "            \n",
    "            \n",
    "        return predictions_absolute_labels\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        return compiled_preds_layer1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745583a",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Here we'll compile and evaluate the four models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df4921",
   "metadata": {},
   "source": [
    "### Model Type-1, Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec451332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the variables here ordered in accordance to the way data dirctories are arranged\n",
    "\n",
    "#Paths can either be .h5 or pb\n",
    "mod_paths = [r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOtherNoex1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOtherNoex1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOtherNoex1\"]\n",
    "\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "plants = [\"Apple\", \"Cherry\", \"Peach\"]\n",
    "\n",
    "class_nums = [4,2,2]\n",
    "\n",
    "predictions = model_type_1(mod_paths, test_path, plants, class_nums, eval_mode = False) \n",
    "\n",
    "########################\n",
    "#Performance analytics\n",
    "\n",
    "#There's probably an easier way to return true classe\n",
    "\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "y_pred = predictions[\"absolute_label\"]\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))\n",
    "\n",
    "#Gets a confidence interval\n",
    "z = 1.96 # 95%\n",
    "accuracy = accuracy_score(testgen.classes, y_pred)\n",
    "conf = z * ((accuracy * (1 - accuracy)) / len(y_pred))**0.5\n",
    "print(\"Accuracy: \" + str(round(accuracy,3)))\n",
    "print(\"95% CI: \" + str(round(accuracy  - conf, 3)) + \" - \" + str(round(accuracy  + conf, 3)))\n",
    "\n",
    "#some of the below plotting code taken from:\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "target_names = testgen.class_indices.keys()\n",
    "type1_noex_plotdf = pd.DataFrame(confusion_matrix(testgen.classes, y_pred),\n",
    "                                 index = list(target_names),\n",
    "                                 columns = list(target_names))\n",
    "\n",
    "type1_noex_plotdf = type1_noex_plotdf.div(list(type1_noex_plotdf.sum(axis=1)), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "ax = sns.heatmap(type1_noex_plotdf.round(3), annot=True, annot_kws={\"size\": 30}, fmt='g', cbar=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel(\"Predicted Class\", fontsize = 50)\n",
    "ax.set_ylabel(\"True Class\", fontsize = 50)\n",
    "ax.set_title('Model Type 1 Exclusive-Other Predictions', fontsize = 65, loc = 'right')\n",
    "ax.tick_params(labelsize=30)\n",
    "\n",
    "plt.savefig(r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Figures\\type1_noex_cm.jpeg\",\n",
    "            bbox_inches = \"tight\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a03e02",
   "metadata": {},
   "source": [
    "### Model Type-1, Inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ea824",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_paths = [r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleDiseaseOther1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryDiseaseOther1\",\n",
    "             r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachDiseaseOther1\"]\n",
    "\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "plants = [\"Apple\", \"Cherry\", \"Peach\"]\n",
    "\n",
    "class_nums = [4,2,2]\n",
    "\n",
    "predictions2 = model_type_1(mod_paths, test_path, plants, class_nums, eval_mode = False) \n",
    "\n",
    "########################\n",
    "#Performance analytics\n",
    "\n",
    "#There's probably an easier way to return true classe\n",
    "\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "y_pred = predictions2[\"absolute_label\"]\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))\n",
    "\n",
    "#Gets a confidence interval\n",
    "z = 1.96 # 95%\n",
    "accuracy = accuracy_score(testgen.classes, y_pred)\n",
    "conf = z * ((accuracy * (1 - accuracy)) / 777)**0.5\n",
    "print(\"Accuracy: \" + str(round(accuracy,3)))\n",
    "print(\"95% CI: \" + str(round(accuracy  - conf, 3)) + \" - \" + str(round(accuracy  + conf, 3)))\n",
    "\n",
    "#some of the below plotting code taken from:\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "target_names = testgen.class_indices.keys()\n",
    "type1_plotdf = pd.DataFrame(confusion_matrix(testgen.classes, y_pred),\n",
    "                                 index = list(target_names),\n",
    "                                 columns = list(target_names))\n",
    "\n",
    "type1_plotdf = type1_plotdf.div(list(type1_plotdf.sum(axis=1)), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "ax = sns.heatmap(type1_plotdf.round(3), annot=True, annot_kws={\"size\": 30}, fmt='g', cbar=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel(\"Predicted Class\", fontsize = 50)\n",
    "ax.set_ylabel(\"True Class\", fontsize = 50)\n",
    "ax.set_title('Model Type 1 Inclusive-Other Predictions', fontsize = 65, loc = 'right')\n",
    "ax.tick_params(labelsize=30)\n",
    "\n",
    "plt.savefig(r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Figures\\type1_cm.jpeg\",\n",
    "            bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca7a09",
   "metadata": {},
   "source": [
    "### Model Type-2, Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08170706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "\n",
    "\n",
    "#####\n",
    "#Paths, plants, and class nums need to be ordered the same as the test set classes are arranged in their directory (probbaly alphabetically)\n",
    "#Otherwise we gotta change how the confusion matrix works\n",
    "#####\n",
    "\n",
    "#Specify layer 1 paths (need to keep same ordering throughout)\n",
    "\n",
    "mod_paths_1 = [r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOtherNoex1',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryOtherNoex1',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachOtherNoex1'\n",
    "               ]\n",
    "\n",
    "#Specify layer 2 paths\n",
    "mod_paths_2 = [r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\Apple1',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Cherry_1_Model.h5',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Peach_1_Model.h5'\n",
    "               ]\n",
    "\n",
    "#Need to provide plant type in the same order as the models\n",
    "#Could probbaly make somthing to infer this automatically\n",
    "plants = [\"Apple\", \"Cherry\", \"Peach\"]\n",
    "\n",
    "#The dataset\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "#The number of classes each layer 2 model can predict (dunno if there's any automatic way to get this info)\n",
    "eval_class_nums = [4,2,2]\n",
    "\n",
    "#Runs the models\n",
    "prediction_aggregate = model_type_2(mod_paths_1, mod_paths_2, test_path, plants, eval_mode = False, eval_class_nums = eval_class_nums)\n",
    "\n",
    "########################\n",
    "#Performance analytics\n",
    "\n",
    "#There's probably an easier way to return true classes\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "y_pred = prediction_aggregate[\"absolute\"]\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))\n",
    "\n",
    "#Gets a confidence interval\n",
    "z = 1.96 # 95%\n",
    "accuracy = accuracy_score(testgen.classes, y_pred)\n",
    "conf = z * ((accuracy * (1 - accuracy)) / len(y_pred))**0.5\n",
    "print(\"Accuracy: \" + str(round(accuracy,3)))\n",
    "print(\"95% CI: \" + str(round(accuracy  - conf, 3)) + \" - \" + str(round(accuracy  + conf, 3)))\n",
    "\n",
    "#some of the below plotting code taken from:\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "target_names = testgen.class_indices.keys()\n",
    "type2_plotnoexdf = pd.DataFrame(confusion_matrix(testgen.classes, y_pred),\n",
    "                                 index = list(target_names),\n",
    "                                 columns = list(target_names))\n",
    "\n",
    "type2_plotnoexdf = type2_plotnoexdf.div(list(type2_plotnoexdf.sum(axis=1)), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "ax = sns.heatmap(type2_plotnoexdf.round(3), annot=True, annot_kws={\"size\": 30}, fmt='g', cbar=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel(\"Predicted Class\", fontsize = 50)\n",
    "ax.set_ylabel(\"True Class\", fontsize = 50)\n",
    "ax.set_title('Model Type 2 Exclusive-Other Predictions', fontsize = 65, loc = 'right')\n",
    "ax.tick_params(labelsize=30)\n",
    "\n",
    "plt.savefig(r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Figures\\type2_noex_cm.jpeg\",\n",
    "            bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60884564",
   "metadata": {},
   "source": [
    "### Model Type-2, Inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dbf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "\n",
    "\n",
    "#####\n",
    "#Paths, plants, and class nums need to be ordered the same as the test set classes are arranged in their directory (probbaly alphabetically)\n",
    "#Otherwise we gotta change how the confusion matrix works\n",
    "#####\n",
    "\n",
    "#Specify layer 1 paths (need to keep same ordering throughout)\n",
    "\n",
    "mod_paths_1 = [r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\AppleOther2',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\CherryOther1',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\PeachesOther1'\n",
    "               ]\n",
    "\n",
    "#Specify layer 2 paths\n",
    "mod_paths_2 = [r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Model_Checkpoints\\Apple1',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Cherry_1_Model.h5',\n",
    "               r'C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Python\\Peach_1_Model.h5'\n",
    "               ]\n",
    "\n",
    "#Need to provide plant type in the same order as the models\n",
    "#Could probbaly make somthing to infer this automatically\n",
    "plants = [\"Apple\", \"Cherry\", \"Peach\"]\n",
    "\n",
    "#The dataset\n",
    "test_path = r\"C:\\Datasets\\Plant Village\\ApplePeachCherryTest\"\n",
    "\n",
    "#The number of classes each layer 2 model can predict (dunno if there's any automatic way to get this info)\n",
    "eval_class_nums = [4,2,2]\n",
    "\n",
    "#Runs the models\n",
    "prediction_aggregate = model_type_2(mod_paths_1, mod_paths_2, test_path, plants, eval_mode = False, eval_class_nums = eval_class_nums)\n",
    "\n",
    "########################\n",
    "#Performance analytics\n",
    "\n",
    "#There's probably an easier way to return true classes\n",
    "testdata = ImageDataGenerator(rescale=1./255)\n",
    "testgen = testdata.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "y_pred = prediction_aggregate[\"absolute\"]\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(testgen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = testgen.class_indices.keys()\n",
    "print(classification_report(testgen.classes, y_pred, target_names=target_names))\n",
    "\n",
    "#Gets a confidence interval\n",
    "z = 1.96 # 95%\n",
    "accuracy = accuracy_score(testgen.classes, y_pred)\n",
    "conf = z * ((accuracy * (1 - accuracy)) / len(y_pred))**0.5\n",
    "print(\"Accuracy: \" + str(round(accuracy,3)))\n",
    "print(\"95% CI: \" + str(round(accuracy  - conf, 3)) + \" - \" + str(round(accuracy  + conf, 3)))\n",
    "\n",
    "#some of the below plotting code taken from:\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "target_names = testgen.class_indices.keys()\n",
    "type2_plotdf = pd.DataFrame(confusion_matrix(testgen.classes, y_pred),\n",
    "                                 index = list(target_names),\n",
    "                                 columns = list(target_names))\n",
    "\n",
    "type2_plotdf = type2_plotdf.div(list(type2_plotdf.sum(axis=1)), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "ax = sns.heatmap(type2_plotdf.round(3), annot=True, annot_kws={\"size\": 30}, fmt='g', cbar=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xlabel(\"Predicted Class\", fontsize = 50)\n",
    "ax.set_ylabel(\"True Class\", fontsize = 50)\n",
    "ax.set_title('Model Type 2 Inclusive-Other Predictions', fontsize = 65, loc = 'right')\n",
    "ax.tick_params(labelsize=30)\n",
    "\n",
    "plt.savefig(r\"C:\\Users\\blume\\OneDrive\\Desktop\\CUNY MSDS\\Data 698 Masters Thesis\\Figures\\type2_cm.jpeg\",\n",
    "            bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
